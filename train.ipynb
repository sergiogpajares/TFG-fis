{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from typing import List, Tuple, Union\n",
    "import enum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 256#512\n",
    "IMG_WIDTH  = 256#512\n",
    "IMG_CHANNELS = 3\n",
    "NUM_CLASSES = 5\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "DATA_DIR = \"dataset\"\n",
    "NUM_TRAIN_IMAGES = 254\n",
    "NUM_VAL_IMAGES = 46\n",
    "NUM_TEST_IMAGES = 46\n",
    "\n",
    "#class ENCODING(enum):\n",
    "#    background = 0\n",
    "#    sky = 1\n",
    "#    sun = 2\n",
    "#    thick_cloud = 3\n",
    "#    thin_cloud = 4\n",
    "#    other = 8\n",
    "\n",
    "# Read images\n",
    "images_path = sorted(glob(os.path.join(DATA_DIR, \"images/*\")))\n",
    "masks_path  = sorted(glob(os.path.join(DATA_DIR, \"masks/*\")))\n",
    "\n",
    "if len(images_path) != len(masks_path):\n",
    "    raise RuntimeError(\"There must be the same number of images and masks!\")\n",
    "\n",
    "\n",
    "# Random shuffle\n",
    "np.random.seed(14092000)\n",
    "perm = np.random.permutation(len(images_path))\n",
    "images_path = [images_path[perm[i]] for i in range(len(images_path))]\n",
    "masks_path = [masks_path[perm[i]] for i in range(len(images_path))]\n",
    "\n",
    "# Divide into train, val and test\n",
    "train_images = images_path[:NUM_TRAIN_IMAGES]\n",
    "train_masks = masks_path[:NUM_TRAIN_IMAGES]\n",
    "val_images = images_path[NUM_TRAIN_IMAGES : NUM_VAL_IMAGES + NUM_TRAIN_IMAGES]\n",
    "val_masks = masks_path[NUM_TRAIN_IMAGES : NUM_VAL_IMAGES + NUM_TRAIN_IMAGES]\n",
    "test_images = images_path[NUM_VAL_IMAGES + NUM_TRAIN_IMAGES : NUM_VAL_IMAGES + NUM_TRAIN_IMAGES + NUM_TEST_IMAGES]\n",
    "test_masks = masks_path[NUM_VAL_IMAGES + NUM_TRAIN_IMAGES : NUM_VAL_IMAGES + NUM_TRAIN_IMAGES + NUM_TEST_IMAGES]\n",
    "\n",
    "train_images = sorted(glob(os.path.join(DATA_DIR,'augmented_images_train','*'))) + train_images\n",
    "train_masks  = sorted(glob(os.path.join(DATA_DIR,'augmented_masks_train','*')))  + train_masks\n",
    "val_images = sorted(glob(os.path.join(DATA_DIR,'augmented_images_val','*'))) + val_images\n",
    "val_masks  = sorted(glob(os.path.join(DATA_DIR,'augmented_masks_val','*')))  + val_masks\n",
    "\n",
    "# Load into tf.data.Dataset\n",
    "def read_image(image_path:str, isMask:bool=False, num_classes=NUM_CLASSES) -> tf.Tensor:\n",
    "    '''\n",
    "    Read either image or mask from its path. Returns a tensor.\n",
    "    \n",
    "    Mask are hot enconded.\n",
    "    '''\n",
    "    image = tf.io.read_file(image_path)\n",
    "    if isMask:\n",
    "        image = tf.image.decode_png(image, channels=1)\n",
    "        image.set_shape([None, None, 1])\n",
    "        image = tf.image.resize(images=image, size=[IMG_WIDTH, IMG_HEIGHT])\n",
    "        image = tf.cast(image, dtype=tf.uint8)\n",
    "        # Other classified as number 8 (check)\n",
    "        if num_classes > 1:\n",
    "            image = tf.keras.utils.to_categorical(image, num_classes = num_classes)\n",
    "            image = tf.squeeze(image,axis=2) #remove extra axis\n",
    "    else:\n",
    "        image = tf.image.decode_png(image, channels=IMG_CHANNELS)\n",
    "        image.set_shape([None, None, IMG_CHANNELS])\n",
    "        image = tf.image.resize(images=image, size=[IMG_WIDTH, IMG_HEIGHT])\n",
    "        image = tf.cast(image, dtype=tf.uint8)\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_data(image_list:List[str], mask_list:List[str]) -> Tuple[tf.Tensor,tf.Tensor]:\n",
    "    '''\n",
    "    Auxiliar function to read both image and mask\n",
    "    '''\n",
    "    image = read_image(image_list)\n",
    "    mask = read_image(mask_list, isMask=True)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def data_generator(image_list:List[str], mask_list:List[str],batch_size:int=BATCH_SIZE) -> tf.data.Dataset:\n",
    "    '''\n",
    "    Return a dataset from a list of images paths\n",
    "    '''\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n",
    "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = data_generator(train_images, train_masks)\n",
    "val_dataset = data_generator(val_images, val_masks)\n",
    "# test_dataset = data_generator(test_images, test_masks)\n",
    "\n",
    "\n",
    "# Ading class weights\n",
    "class_weights = tf.constant([1,1,5,1,0.8])\n",
    "def map_weights(image, label):\n",
    "    # Assuming label is one-hot encoded, calculate weights based on the class\n",
    "    weights = tf.reduce_sum(label * class_weights, axis=-1)  # Calculate weights based on class\n",
    "    return image, label, weights\n",
    "\n",
    "# Map the function to the dataset\n",
    "train_dataset = train_dataset.map(map_weights)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Train Dataset:  \", train_dataset)\n",
    "print(\"Val Dataset:  \", val_dataset)\n",
    "# print(\"Test Dataset:  \", test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_side = 3\n",
    "conv_trans_side = 3\n",
    "conv_trans_strides_side = 2\n",
    "pool_side = 2\n",
    "\n",
    "def multi_unet_model(n_classes:int=NUM_CLASSES, img_height:int=IMG_HEIGHT, img_width:int=IMG_WIDTH, img_channels:int=IMG_CHANNELS) -> keras.models.Model:\n",
    "    '''\n",
    "    Build the model\n",
    "    '''\n",
    "    inputs = keras.layers.Input((img_height, img_width, img_channels))\n",
    "    s = keras.layers.Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
    "\n",
    "    #Contraction path\n",
    "    c1 = keras.layers.Conv2D(16, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = keras.layers.Dropout(0.1)(c1)\n",
    "    c1 = keras.layers.Conv2D(16, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = keras.layers.MaxPooling2D((pool_side, pool_side))(c1)\n",
    "    b1 = tf.keras.layers.BatchNormalization(synchronized=True)(p1)\n",
    "    \n",
    "    c2 = keras.layers.Conv2D(32, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(b1)\n",
    "    c2 = keras.layers.Dropout(0.1)(c2)\n",
    "    c2 = keras.layers.Conv2D(32, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = keras.layers.MaxPooling2D((pool_side, pool_side))(c2)\n",
    "    b2 = tf.keras.layers.BatchNormalization(synchronized=True)(p2)\n",
    "     \n",
    "    c3 = keras.layers.Conv2D(64, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(b2)\n",
    "    c3 = keras.layers.Dropout(0.2)(c3)\n",
    "    c3 = keras.layers.Conv2D(64, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = keras.layers.MaxPooling2D((pool_side, pool_side))(c3)\n",
    "    b3 = tf.keras.layers.BatchNormalization(synchronized=True)(p3)\n",
    "     \n",
    "    c4 = keras.layers.Conv2D(128, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(b3)\n",
    "    c4 = keras.layers.Dropout(0.2)(c4)\n",
    "    c4 = keras.layers.Conv2D(128, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = keras.layers.MaxPooling2D(pool_size=(pool_side, pool_side))(c4)\n",
    "    b4 = tf.keras.layers.BatchNormalization(synchronized=True)(p4)\n",
    "     \n",
    "    c5 = keras.layers.Conv2D(256, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(b4)\n",
    "    c5 = keras.layers.Dropout(0.3)(c5)\n",
    "    c5 = keras.layers.Conv2D(256, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    \n",
    "    #Expansive path \n",
    "    u6 = keras.layers.Conv2DTranspose(128, (conv_trans_side, conv_trans_side), strides=(conv_trans_strides_side, conv_trans_strides_side), padding='same')(c5)\n",
    "    u6 = keras.layers.concatenate([u6, c4])\n",
    "    c6 = keras.layers.Conv2D(128, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = keras.layers.Dropout(0.2)(c6)\n",
    "    c6 = keras.layers.Conv2D(128, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "    b6 = tf.keras.layers.BatchNormalization(synchronized=True)(c6)\n",
    "     \n",
    "    u7 = keras.layers.Conv2DTranspose(64, (conv_trans_side, conv_trans_side), strides=(conv_trans_strides_side, conv_trans_strides_side), padding='same')(b6)\n",
    "    u7 = keras.layers.concatenate([u7, c3])\n",
    "    c7 = keras.layers.Conv2D(64, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = keras.layers.Dropout(0.2)(c7)\n",
    "    c7 = keras.layers.Conv2D(64, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "    b7 = tf.keras.layers.BatchNormalization(synchronized=True)(c7)\n",
    "    \n",
    "    u8 = keras.layers.Conv2DTranspose(32, (conv_trans_side, conv_trans_side), strides=(conv_trans_strides_side, conv_trans_strides_side), padding='same')(b7)\n",
    "    u8 = keras.layers.concatenate([u8, c2])\n",
    "    c8 = keras.layers.Conv2D(32, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = keras.layers.Dropout(0.1)(c8)\n",
    "    c8 = keras.layers.Conv2D(32, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "    b8 = tf.keras.layers.BatchNormalization(synchronized=True)(c8)\n",
    "     \n",
    "    u9 = keras.layers.Conv2DTranspose(16, (conv_trans_side, conv_trans_side), strides=(conv_trans_strides_side, conv_trans_strides_side), padding='same')(b8)\n",
    "    u9 = keras.layers.concatenate([u9, c1], axis=3)\n",
    "    c9 = keras.layers.Conv2D(16, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = keras.layers.Dropout(0.1)(c9)\n",
    "    c9 = keras.layers.Conv2D(16, (conv_side, conv_side), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "     \n",
    "    outputs = keras.layers.Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
    "     \n",
    "    model = keras.models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = multi_unet_model()\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\n",
    "        tf.keras.metrics.OneHotIoU(\n",
    "            num_classes=NUM_CLASSES,\n",
    "            target_class_ids=[i for i in range(NUM_CLASSES)],\n",
    "            sparse_y_pred = False # when false retrive prediction with tf.argmax\n",
    "        ),\n",
    "    ]\n",
    "#     loss_weights=None,\n",
    "#     weighted_metrics=None,\n",
    "#     run_eagerly=None,\n",
    "#     steps_per_execution=None,\n",
    "#     jit_compile=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=10,\n",
    "        monitor='val_loss'\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=5,\n",
    "#         verbose=0,\n",
    "        mode='auto',\n",
    "        min_delta=0.0001,\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir='logs'\n",
    "    ),\n",
    "    tf.keras.callbacks.History(\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x=train_dataset,\n",
    "#     y=None,\n",
    "#     batch_size=None,\n",
    "    epochs=300,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "#     validation_split=0.0,\n",
    "    validation_data=val_dataset,\n",
    "    shuffle=True,\n",
    "#     class_weight=None,\n",
    "#     sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "#     steps_per_epoch=None,\n",
    "#     validation_steps=None,\n",
    "#     validation_batch_size=None,\n",
    "#     validation_freq=1,\n",
    "#     max_queue_size=10,\n",
    "#     workers=1,\n",
    "#     use_multiprocessing=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_loss'],'r-', label='Validation Loss')\n",
    "plt.plot(history.history['loss'],'r--', label='Loss')\n",
    "plt.plot(history.history['one_hot_io_u_4'],'b--',label='IoU')\n",
    "plt.plot(history.history['val_one_hot_io_u_4'],'b-',label='Validation IOU')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.xlim(0)\n",
    "plt.ylim(0)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_map(mask:tf.Tensor) -> np.ndarray:\n",
    "    '''\n",
    "    Turn an 1-encoded gray image into a colored image\n",
    "    '''\n",
    "    background_color = (0,0,0) # black\n",
    "    clear_sky = (92, 179, 255) # clear blue\n",
    "    thin_cloud = (255, 243, 245) # shiny gray\n",
    "    tick_cloud = (113, 125, 150) # deep gray\n",
    "    sun = (255, 242, 0) # yellow\n",
    "    \n",
    "    colored_image = np.empty((mask.shape[0],mask.shape[1],3),dtype=np.uint8)\n",
    "    \n",
    "    \n",
    "    for class_index, color in enumerate([background_color,clear_sky,sun,tick_cloud,thin_cloud]):\n",
    "        indices = np.where(mask == class_index)\n",
    "        colored_image[indices[0],indices[1],:] = color\n",
    "    return colored_image\n",
    "\n",
    "def multipredict(img_list:List[str],mask_list:List[str],model:keras.Model=model) -> None:\n",
    "    if len(img_list) != len(mask_list):\n",
    "        raise ValueError('There must be the same number os masks and images')\n",
    "    if len(img_list) == 0:\n",
    "        raise ValueError('There must be at least one image')\n",
    "    \n",
    "    fig, ax = plt.subplots(len(img_list),3,figsize=(12,4*len(img_list)+3))\n",
    "    index = 0 # row counter\n",
    "    for img_path, mask_path in zip(img_list,mask_list):\n",
    "        img = read_image(img_path)\n",
    "        ax[index,0].imshow( img )\n",
    "        ax[index,0].set_xticks([])\n",
    "        ax[index,0].set_yticks([])\n",
    "        \n",
    "        pred = model.predict( tf.expand_dims(img,0) )\n",
    "        ax[index,1].imshow( color_map(tf.argmax(pred[0,:,:,:],2)) )\n",
    "        ax[index,1].set_xticks([])\n",
    "        ax[index,1].set_yticks([])\n",
    "        \n",
    "        ax[index,2].imshow(color_map(read_image(mask_path)[:,:,0]))\n",
    "        ax[index,2].set_xticks([])\n",
    "        ax[index,2].set_yticks([])\n",
    "        \n",
    "        index += 1\n",
    "    \n",
    "    ax[0,0].set_title(\"Image\")\n",
    "    ax[0,1].set_title(\"Inference\")\n",
    "    ax[0,2].set_title(\"Ground truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multipredict(test_images,test_masks)\n",
    "plt.savefig(\"TestPrediction3.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
